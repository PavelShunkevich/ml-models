digraph {
	graph [size="24.75,24.75"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	1186427549840 [label="
 (1, 10)" fillcolor=darkolivegreen1]
	1186464344256 [label=AddmmBackward0]
	1186490680272 -> 1186464344256
	1186427550480 [label="fc2.bias
 (10)" fillcolor=lightblue]
	1186427550480 -> 1186490680272
	1186490680272 [label=AccumulateGrad]
	1186489301408 -> 1186464344256
	1186489301408 [label=MulBackward0]
	1186278399792 -> 1186489301408
	1186278399792 [label=ReluBackward0]
	1186278401520 -> 1186278399792
	1186278401520 [label=AddmmBackward0]
	1186491543616 -> 1186278401520
	1186427543920 [label="fc1.bias
 (128)" fillcolor=lightblue]
	1186427543920 -> 1186491543616
	1186491543616 [label=AccumulateGrad]
	1186491545920 -> 1186278401520
	1186491545920 [label=ViewBackward0]
	1186491546112 -> 1186491545920
	1186491546112 [label=MeanBackward1]
	1186491546160 -> 1186491546112
	1186491546160 [label=ReluBackward0]
	1186491546352 -> 1186491546160
	1186491546352 [label=AddBackward0]
	1186491546400 -> 1186491546352
	1186491546400 [label=NativeBatchNormBackward0]
	1186491546544 -> 1186491546400
	1186491546544 [label=ConvolutionBackward0]
	1186491546736 -> 1186491546544
	1186491546736 [label=ReluBackward0]
	1186491546880 -> 1186491546736
	1186491546880 [label=NativeBatchNormBackward0]
	1186491546976 -> 1186491546880
	1186491546976 [label=ConvolutionBackward0]
	1186491547168 -> 1186491546976
	1186491547168 [label=ReluBackward0]
	1186491547312 -> 1186491547168
	1186491547312 [label=AddBackward0]
	1186491547408 -> 1186491547312
	1186491547408 [label=NativeBatchNormBackward0]
	1186491547552 -> 1186491547408
	1186491547552 [label=ConvolutionBackward0]
	1186491760800 -> 1186491547552
	1186491760800 [label=ReluBackward0]
	1186491760944 -> 1186491760800
	1186491760944 [label=NativeBatchNormBackward0]
	1186491761040 -> 1186491760944
	1186491761040 [label=ConvolutionBackward0]
	1186491761232 -> 1186491761040
	1186491761232 [label=ReluBackward0]
	1186491761376 -> 1186491761232
	1186491761376 [label=NativeBatchNormBackward0]
	1186491761472 -> 1186491761376
	1186491761472 [label=ConvolutionBackward0]
	1186491761664 -> 1186491761472
	1186427537760 [label="conv1.weight
 (64, 3, 3, 3)" fillcolor=lightblue]
	1186427537760 -> 1186491761664
	1186491761664 [label=AccumulateGrad]
	1186491761712 -> 1186491761472
	1186427537600 [label="conv1.bias
 (64)" fillcolor=lightblue]
	1186427537600 -> 1186491761712
	1186491761712 [label=AccumulateGrad]
	1186491761520 -> 1186491761376
	1186427537520 [label="bn1.weight
 (64)" fillcolor=lightblue]
	1186427537520 -> 1186491761520
	1186491761520 [label=AccumulateGrad]
	1186491761328 -> 1186491761376
	1186427537360 [label="bn1.bias
 (64)" fillcolor=lightblue]
	1186427537360 -> 1186491761328
	1186491761328 [label=AccumulateGrad]
	1186491761280 -> 1186491761040
	1186427536640 [label="res_block1.conv1.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	1186427536640 -> 1186491761280
	1186491761280 [label=AccumulateGrad]
	1186491761088 -> 1186491760944
	1186427536560 [label="res_block1.bn1.weight
 (128)" fillcolor=lightblue]
	1186427536560 -> 1186491761088
	1186491761088 [label=AccumulateGrad]
	1186491760896 -> 1186491760944
	1186427536400 [label="res_block1.bn1.bias
 (128)" fillcolor=lightblue]
	1186427536400 -> 1186491760896
	1186491760896 [label=AccumulateGrad]
	1186491760848 -> 1186491547552
	1186427535680 [label="res_block1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1186427535680 -> 1186491760848
	1186491760848 [label=AccumulateGrad]
	1186491547600 -> 1186491547408
	1186427535600 [label="res_block1.bn2.weight
 (128)" fillcolor=lightblue]
	1186427535600 -> 1186491547600
	1186491547600 [label=AccumulateGrad]
	1186491547504 -> 1186491547408
	1186427545280 [label="res_block1.bn2.bias
 (128)" fillcolor=lightblue]
	1186427545280 -> 1186491547504
	1186491547504 [label=AccumulateGrad]
	1186491547456 -> 1186491547312
	1186491547456 [label=NativeBatchNormBackward0]
	1186491760992 -> 1186491547456
	1186491760992 [label=ConvolutionBackward0]
	1186491761232 -> 1186491760992
	1186491761184 -> 1186491760992
	1186427551600 [label="res_block1.shortcut.0.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	1186427551600 -> 1186491761184
	1186491761184 [label=AccumulateGrad]
	1186491760752 -> 1186491547456
	1186427544960 [label="res_block1.shortcut.1.weight
 (128)" fillcolor=lightblue]
	1186427544960 -> 1186491760752
	1186491760752 [label=AccumulateGrad]
	1186491760704 -> 1186491547456
	1186427544880 [label="res_block1.shortcut.1.bias
 (128)" fillcolor=lightblue]
	1186427544880 -> 1186491760704
	1186491760704 [label=AccumulateGrad]
	1186491547216 -> 1186491546976
	1186427551280 [label="res_block2.conv1.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	1186427551280 -> 1186491547216
	1186491547216 [label=AccumulateGrad]
	1186491547024 -> 1186491546880
	1186427544640 [label="res_block2.bn1.weight
 (256)" fillcolor=lightblue]
	1186427544640 -> 1186491547024
	1186491547024 [label=AccumulateGrad]
	1186491546832 -> 1186491546880
	1186427544560 [label="res_block2.bn1.bias
 (256)" fillcolor=lightblue]
	1186427544560 -> 1186491546832
	1186491546832 [label=AccumulateGrad]
	1186491546784 -> 1186491546544
	1186427550960 [label="res_block2.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1186427550960 -> 1186491546784
	1186491546784 [label=AccumulateGrad]
	1186491546592 -> 1186491546400
	1186427544320 [label="res_block2.bn2.weight
 (256)" fillcolor=lightblue]
	1186427544320 -> 1186491546592
	1186491546592 [label=AccumulateGrad]
	1186491546496 -> 1186491546400
	1186427544240 [label="res_block2.bn2.bias
 (256)" fillcolor=lightblue]
	1186427544240 -> 1186491546496
	1186491546496 [label=AccumulateGrad]
	1186491546448 -> 1186491546352
	1186491546448 [label=NativeBatchNormBackward0]
	1186491546928 -> 1186491546448
	1186491546928 [label=ConvolutionBackward0]
	1186491547168 -> 1186491546928
	1186491547120 -> 1186491546928
	1186427550640 [label="res_block2.shortcut.0.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	1186427550640 -> 1186491547120
	1186491547120 [label=AccumulateGrad]
	1186491546688 -> 1186491546448
	1186427543840 [label="res_block2.shortcut.1.weight
 (256)" fillcolor=lightblue]
	1186427543840 -> 1186491546688
	1186491546688 [label=AccumulateGrad]
	1186491546640 -> 1186491546448
	1186427543760 [label="res_block2.shortcut.1.bias
 (256)" fillcolor=lightblue]
	1186427543760 -> 1186491546640
	1186491546640 [label=AccumulateGrad]
	1186491541216 -> 1186278401520
	1186491541216 [label=TBackward0]
	1186491546256 -> 1186491541216
	1186427550320 [label="fc1.weight
 (128, 256)" fillcolor=lightblue]
	1186427550320 -> 1186491546256
	1186491546256 [label=AccumulateGrad]
	1186464339600 -> 1186464344256
	1186464339600 [label=TBackward0]
	1186278401712 -> 1186464339600
	1186427550560 [label="fc2.weight
 (10, 128)" fillcolor=lightblue]
	1186427550560 -> 1186278401712
	1186278401712 [label=AccumulateGrad]
	1186464344256 -> 1186427549840
}
